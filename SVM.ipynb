{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NisaHameed/NisaHameed/blob/main/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T90cX4ichklP"
      },
      "source": [
        "\n",
        "# Support Vector Machines\n",
        "\n",
        "One thing SVMs are very good at is text classification.\n",
        "\n",
        "The goal here is to determine whether a tweet was written by a Democratic or Republican politician, using just the text of the tweet.\n",
        "\n",
        "`sklearn` library is used in this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICj3ClLyhklU"
      },
      "source": [
        "The data has three fields:\n",
        "\n",
        "| Feature \t| Description               \t|\n",
        "|---------\t|---------------------------\t|\n",
        "|   Party \t| Democrat or Republican    \t|\n",
        "|  Handle \t| The author's Twitter name \t|\n",
        "|   Tweet \t| The text of the tweet     \t|"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        " \n",
        " \n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "v0X01nwrApoW",
        "outputId": "8a6d4938-9eff-480b-a3be-0fbf43185485"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f5e002a5-00a0-44de-83e7-50293383a046\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f5e002a5-00a0-44de-83e7-50293383a046\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tweets.csv to tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L6UDOfFbhklV",
        "outputId": "1e9a18e1-e931-4b9a-92cc-5d421e007ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Party           Handle  \\\n",
              "4098     Democrat   RepStephMurphy   \n",
              "39638    Democrat         cbrangel   \n",
              "44277  Republican  RepPaulMitchell   \n",
              "70181  Republican         RepDavid   \n",
              "32440    Democrat  BennieGThompson   \n",
              "\n",
              "                                                   Tweet  \n",
              "4098   RT @SSNAlerts: .@RepStephMurphy's, Mike Kelly'...  \n",
              "39638  America is greater thx to contributions of Lat...  \n",
              "44277  Speaking to @therealnmma this morning about my...  \n",
              "70181  RT @DodieLondenEIPS: Congratulations to Britta...  \n",
              "32440  Republicans control the House, Senate and Whit...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcd4c4ad-a276-4b08-8231-72f4f684158d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4098</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepStephMurphy</td>\n",
              "      <td>RT @SSNAlerts: .@RepStephMurphy's, Mike Kelly'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39638</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>cbrangel</td>\n",
              "      <td>America is greater thx to contributions of Lat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44277</th>\n",
              "      <td>Republican</td>\n",
              "      <td>RepPaulMitchell</td>\n",
              "      <td>Speaking to @therealnmma this morning about my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70181</th>\n",
              "      <td>Republican</td>\n",
              "      <td>RepDavid</td>\n",
              "      <td>RT @DodieLondenEIPS: Congratulations to Britta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32440</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>BennieGThompson</td>\n",
              "      <td>Republicans control the House, Senate and Whit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcd4c4ad-a276-4b08-8231-72f4f684158d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcd4c4ad-a276-4b08-8231-72f4f684158d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcd4c4ad-a276-4b08-8231-72f4f684158d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "data = pd.read_csv(io.BytesIO(uploaded['tweets.csv']))\n",
        "\n",
        "# Training an SVM on a lot of data with a lot of features can take a few minutes,\n",
        "# so to keep things speedy here we will use a subset of the data.\n",
        "data = data.sample(5000, random_state=5)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "snJQ91T6AneT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e75pKcI0hklW"
      },
      "source": [
        "## Looking at the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agrR_Q1ThklW"
      },
      "source": [
        "How many politicians do we have tweets from, per party?\n",
        "\n",
        "(Not how many tweets per party!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3PFYvrmmhklW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a130dc0a-d7cb-4f21-9439-a66ecf17083c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Republican    222\n",
              "Democrat      211\n",
              "Name: Party, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.drop_duplicates(subset='Handle')['Party'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn55DQqQhklX"
      },
      "source": [
        "And how many tweets per politician?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FdOWdL_RhklX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2893afc0-e98f-4ee7-833b-d610186b12df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Handle\n",
              "AGBecerra          16\n",
              "AlanGrayson        18\n",
              "AnthonyBrownMD4     5\n",
              "AustinScottGA08     9\n",
              "BennieGThompson     6\n",
              "                   ..\n",
              "reppittenger       15\n",
              "repsandylevin      11\n",
              "rosadelauro        12\n",
              "sethmoulton         9\n",
              "virginiafoxx        7\n",
              "Name: Tweet, Length: 433, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.groupby('Handle')['Tweet'].agg('count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piOmrVcShklY"
      },
      "source": [
        "## Working with text data\n",
        "\n",
        "The features for an SVM can't be words or whole tweets. We need a numerical representation for the words in the texts. One method is to transform the text into TF-IDF vectors.\n",
        "\n",
        "It will take the tweets, tokenise them into words (using a special tokeniser that knows how best to split up tweets), remove stop words (very common words like \"the\" and \"and\", which do not really contribute to the meaning of a tweet much) then it will create a sparse matrix representation of all the tweets. Each row is a single tweet, each column is a word in the vocabulary of all the tweets.\n",
        "\n",
        "It only uses the 5000 most common words - using all ~200k words would take a long time to train a model.\n",
        "\n",
        "(This will take a few seconds!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you need to install twokenize. You can run this cell only once\n",
        "!pip install twokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km_Np6Z3evuW",
        "outputId": "863fedb4-1a7b-4629-eb36-26ae1e33ba88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting twokenize\n",
            "  Downloading twokenize-1.0.0-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: twokenize\n",
            "Successfully installed twokenize-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "glRRmyW4hklY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a239d844-a6c0-4e46-83ef-cdb903dcf07d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5000x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 53445 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import twokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "transformer = TfidfVectorizer(tokenizer=twokenize.tokenizeRawTweetText, stop_words='english', max_features=5000)\n",
        "tweet_vecs = transformer.fit_transform(data['Tweet'])\n",
        "\n",
        "tweet_vecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qvC_PfIOhklZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5192313-0169-4b14-b026-dfa31857cf6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rt', 4015),\n",
              " (':', 503),\n",
              " ('.', 325),\n",
              " (',', 318),\n",
              " ('mike', 3219),\n",
              " ('cracking', 1671),\n",
              " ('house', 2625),\n",
              " ('…', 4977),\n",
              " ('america', 985),\n",
              " ('greater', 2422)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Some words in the vocabulary and their IDs\n",
        "\n",
        "list(transformer.vocabulary_.items())[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ynW7uv7hklZ"
      },
      "source": [
        "## Setting up the data\n",
        "\n",
        "As is standard, we will use some of our data for training the model and some of it for evaluating it. This gives a better idea of how well the model can generalise to unseen data, rather than simply overfitting to the data it has seen.\n",
        "\n",
        "First, we set up a variable `y` to store the Party labels we want to predict.\n",
        "\n",
        "Then, we use the `train_test_split` function to split up the `tweet_vecs` and the `y` data into train/test portions, using an 80:20 train:test ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Gf3xtiYjhkla"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = data['Party']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweet_vecs, y, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i-l5eQ9hklb"
      },
      "source": [
        "## Task 1: Train a linear kernel SVM\n",
        "\n",
        "SVMs in `sklearn` have a few configurable options. The key ones are the kernel to be used (which can overcome non-separable data classes) and the regularization value $C$ (to relax or tighten the margins).\n",
        "\n",
        "Use a `for` loop to try different values for the kernel: `['linear', 'rbf', 'poly', 'sigmoid']`\n",
        "\n",
        "On each iteration, create a classifier with that `kernel`, and call `.fit()` with the training data.\n",
        "\n",
        "Then, use the `.score()` method to see how well the model did on both the seen and the unseen data. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "scrolled": true,
        "id": "JSDFtighhklb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bcef93-f78f-4713-ba71-2a613867111c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KERNEL TYPE:  linear\n",
            "Training score (accuracy) :  0.954\n",
            "Testing score (accuracy) :  0.666\n",
            "\n",
            "KERNEL TYPE:  rbf\n",
            "Training score (accuracy) :  0.99675\n",
            "Testing score (accuracy) :  0.677\n",
            "\n",
            "KERNEL TYPE:  poly\n",
            "Training score (accuracy) :  0.99675\n",
            "Testing score (accuracy) :  0.67\n",
            "\n",
            "KERNEL TYPE:  sigmoid\n",
            "Training score (accuracy) :  0.85\n",
            "Testing score (accuracy) :  0.667\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kernels=['linear', 'rbf', 'poly', 'sigmoid']\n",
        "for kernel_type in kernels:\n",
        "  print(\"\\nKERNEL TYPE: \",kernel_type)\n",
        "  clf = svm.SVC(kernel=kernel_type, C = 2.5)\n",
        "  #SVM for Training data\n",
        "  clf.fit(X_train,y_train)\n",
        "  score_train = clf.score(X_train, y_train)\n",
        "  print(\"Training score (accuracy) : \",score_train)\n",
        "\n",
        "  #SVM for Test data\n",
        "  score_test = clf.score(X_test, y_test)\n",
        "  print(\"Testing score (accuracy) : \",score_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2dVcl9Fhklb"
      },
      "source": [
        "## Task 2: Find the best model parameters\n",
        "\n",
        "In addition to testing different kernels, try different values for $C$, the regularization hyperparameter.\n",
        "\n",
        "Rather than doing this in a loop, one model at a time, we can parallelise it using `GridSearchCV` in `sklearn`. \n",
        "\n",
        "The `GridSearchCV` class takes a model, with a dictionary of hyperparameters and values. Then you just fit/train it as usual, using the training data from before.\n",
        "\n",
        "Try the following:\n",
        "\n",
        "1. Different kernels\n",
        "2. A few values for $C$\n",
        "\n",
        "Below, create a `GridSearchCV` in the same way you would do with a model: assign it to a variable named `gcv`, pass it the `classifier` as your basic model without parameters set, and also pass it `params`.\n",
        "\n",
        "To speed things up, set `n_jobs=-1` to use all available CPU cores. Set `verbose=1` so you get updates as it proceeds - useful for making sure it is actually working!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yh2JFsl2hklc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe99a46-944e-4534-cb25-5bcb5924aefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
            "Best params :  {'C': 1.3, 'kernel': 'rbf'}\n",
            "Best estimator :  SVC(C=1.3)\n",
            "Best score :  0.6759999999999999\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#params = dict(kernel=['linear', 'rbf', 'poly', 'sigmoid'],C=[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5, 1.7, 2.0],)\n",
        "param_grid = {'C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5, 1.7, 2.0],'kernel': ['linear', 'rbf', 'poly', 'sigmoid']} \n",
        "\n",
        "classifier = SVC()\n",
        "\n",
        "#GridSearchCV(estimator=SVC(), n_jobs=-1,param_grid={'C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5, 1.7,2.0],\n",
        "                                                       # 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},verbose=1)\n",
        "                                                      \n",
        "gcv=GridSearchCV(classifier, param_grid, refit = True, verbose = 1)\n",
        "gcv.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(\"Best params : \",gcv.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(\"Best estimator : \",gcv.best_estimator_)\n",
        "print(\"Best score : \",gcv.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AUn_Y9Shklc"
      },
      "source": [
        "## What was the best model?\n",
        "\n",
        "`GridSearchCV` evaluated each possible model using the accuracy metric.\n",
        "\n",
        "The best model is stored inside `gcv` as `best_estimator_`. Its score is in `gcv.best_score_` and the actual hyperparameters used are in `gcv.best_params_`.\n",
        "\n",
        "(The score here is not the score on the training set, but the average score across subsets of the training set.)\n",
        "\n",
        "Take a look at these and then evaluate the best model using the test set.\n",
        "\n",
        "How does it compare to the four models you trained before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VnoKOCJfhklc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b1447f-6455-4184-a078-7082426d5559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
            "Best params :  {'C': 1.3, 'kernel': 'rbf'}\n",
            "Best estimator :  SVC(C=1.3)\n",
            "Best score :  0.6479999999999999\n"
          ]
        }
      ],
      "source": [
        "# Best fit for Test data\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#params = dict(kernel=['linear', 'rbf', 'poly', 'sigmoid'],C=[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5, 1.7, 2.0],)\n",
        "\n",
        "param_grid = {'C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5, 1.7, 2.0],'kernel': ['linear', 'rbf', 'poly', 'sigmoid']} \n",
        "\n",
        "classifier = SVC()\n",
        "\n",
        "#GridSearchCV(estimator=SVC(), n_jobs=-1,param_grid={'C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5, 1.7,2.0],\n",
        "                                                       # 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},verbose=1)\n",
        "                                                      \n",
        "gcv=GridSearchCV(classifier, param_grid, refit = True, verbose = 1)\n",
        "gcv.fit(X_test, y_test)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(\"Best params : \",gcv.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(\"Best estimator : \",gcv.best_estimator_)\n",
        "print(\"Best score : \",gcv.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXg8JK5Thklc"
      },
      "source": [
        "## What is easier to classify? Democrat or Republican?\n",
        "\n",
        "Accuracy only gives one impression. We have three classes here, so print a classification report for each of the baseline models.\n",
        "\n",
        "`sklearn.metrics.classification_report` takes two arguments: the true labels and a model's predictions.\n",
        "\n",
        "You can get predictions for `X_test` by using the `.predict()` method of a trained model.\n",
        "\n",
        "How does the best model do at predicting the two classes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5gMutKv5hklc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d71de4-9583-4d9c-f5b6-50f60ec61c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "CLASSIFICATION REPORT - LOGISTIC REGRESSION\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Democrat       0.68      0.66      0.67       481\n",
            "  Republican       0.69      0.71      0.70       519\n",
            "\n",
            "    accuracy                           0.69      1000\n",
            "   macro avg       0.69      0.69      0.69      1000\n",
            "weighted avg       0.69      0.69      0.69      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_predict=model.predict(X_test)\n",
        "print(y_test.shape)\n",
        "print(y_predict.shape)\n",
        "\n",
        "print(\"CLASSIFICATION REPORT - LOGISTIC REGRESSION\\n\",classification_report(y_test, y_predict))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}